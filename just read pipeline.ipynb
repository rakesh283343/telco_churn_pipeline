{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "import kfp\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "\n",
    "def rf_model(file_name: str, n_estimators: int) -> NamedTuple('Outputs', [('Cf1', int), ('Cf2', int),\n",
    "                                                                                     ('Cf3', int), ('Cf4', int)]):\n",
    "        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import string\n",
    "    import urllib\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv\"\n",
    "    file = urllib.request.urlopen(url)\n",
    "    l = []\n",
    "    for line in file:\n",
    "        decoded_line = line.decode()\n",
    "        l.append(decoded_line.split(',')[:-1])\n",
    "    df_churn = pd.DataFrame(l[1:], columns=l[0])\n",
    "    empty_cols=['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "           'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "           'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport',\n",
    "           'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "           'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
    "\n",
    "    for i in empty_cols:\n",
    "        df_churn[i]=df_churn[i].replace(\" \",np.nan)\n",
    "\n",
    "    df_churn.drop(['customerID'], axis=1, inplace=True)\n",
    "    df_churn = df_churn.dropna()\n",
    "    binary_cols = ['Partner','Dependents','PhoneService','PaperlessBilling']\n",
    "\n",
    "    for i in binary_cols:\n",
    "        df_churn[i] = df_churn[i].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "    #Encoding column 'gender'\n",
    "    df_churn['gender'] = df_churn['gender'].replace({\"Male\":1,\"Female\":0})\n",
    "\n",
    "\n",
    "    category_cols = ['PaymentMethod','MultipleLines','InternetService','OnlineSecurity',\n",
    "                   'OnlineBackup','DeviceProtection',\n",
    "                   'TechSupport','StreamingTV','StreamingMovies','Contract']\n",
    "\n",
    "    for cc in category_cols:\n",
    "        dummies = pd.get_dummies(df_churn[cc], drop_first=False)\n",
    "        dummies = dummies.add_prefix(\"{}#\".format(cc))\n",
    "        df_churn.drop(cc, axis=1, inplace=True)\n",
    "        df_churn = df_churn.join(dummies)\n",
    "\n",
    "    df_churn['Churn'] = df_churn['Churn'].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "\n",
    "    df1 = df_churn.loc[:,:'Churn']\n",
    "    df1_int = df1[set(df1.columns)-{'tenure','MonthlyCharges','TotalCharges'}]\n",
    "    df1_float = df1[['tenure','MonthlyCharges','TotalCharges']]\n",
    "    df2 = df_churn.loc[:,'PaymentMethod#Bank transfer (automatic)':]\n",
    "\n",
    "    def get_item(a):\n",
    "        return int(a)\n",
    "\n",
    "    def get_fl(a):\n",
    "        return float(a)\n",
    "\n",
    "    df1_int = df1_int.applymap(get_item)\n",
    "    df1_float = df1_float.applymap(get_fl)\n",
    "    df2 = df2.applymap(get_item)\n",
    "    df_churn = df1_int.join(df1_float.join(df2))\n",
    "    df_churn.dropna(inplace=True)\n",
    "\n",
    "    n_estimators = 100\n",
    "    n_est = n_estimators\n",
    "\n",
    "    y1 = df_churn['Churn']\n",
    "    X1 = df_churn.drop(['Churn'],axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)\n",
    "\n",
    "\n",
    "    sm = SMOTE(random_state=0)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    X_test_res, y_test_res = sm.fit_sample(X_test, y_test)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth' : [2,4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    import xgboost as xgb\n",
    "\n",
    "    clfxg = xgb.XGBClassifier(objective='binary:logistic', verbosity=0, max_depth=2, eta = 1, silent=0)\n",
    "    clfxg.fit(X_train_res, y_train_res) #, num_round, watchlist)\n",
    "\n",
    "    y_test_pred = clfxg.predict(X_test_res)\n",
    "    conf = confusion_matrix(y_test_res, y_test_pred)\n",
    "    \n",
    "    return (conf[0][0], conf[0][1], conf[1][0], conf[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_rf_model = kfp.components.func_to_container_op(func = rf_model, \n",
    "                                                          output_component_file = './rf-model-func.yaml',\n",
    "                                                          packages_to_install = ['scikit-learn==0.22.2','numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3',\n",
    "                                                                                 'imbalanced-learn==0.6.2','urllib3==1.24.2', 'xgboost==1.0.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "\n",
    "@dsl.pipeline(name='Read-Pipeline',description='ions using Random Forest Algorithm')\n",
    "def Justread_func(file_name = \"https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv\", \n",
    "                n_estimators = 100):\n",
    "    \n",
    "    #Passing pipeline parameter and a constant value as operation arguments\n",
    "\n",
    "    rf_model_task = kfp_rf_model(file_name, n_estimators = 100)\n",
    "\n",
    "#For an operation with a single return value, the output reference can be accessed using `task.output` or `task.outputs['output_name']` syntax\n",
    "#For an operation with a multiple return values, the output references can be accessed using `task.outputs['output_name']` syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline_func = Justread_func\n",
    "pipeline_filename = pipeline_func.__name__+'.pipeline.tar.gz'\n",
    "\n",
    "import kfp.compiler as comp\n",
    "comp.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
