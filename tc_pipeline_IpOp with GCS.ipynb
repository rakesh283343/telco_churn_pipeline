{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data\n",
    "\n",
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def read_data(file_name: str, df_churn_op :OutputPath()): \n",
    "        \n",
    "    ## Import Required Libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    df_churn = pd.read_csv(file_name)\n",
    "    df_churn.to_csv(df_churn_op, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_read_data = kfp.components.func_to_container_op(func = read_data, \n",
    "                                                          output_component_file = './read-data-func.yaml',\n",
    "                                                          packages_to_install = ['numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def one_hot_encode(df_churn_ip: InputPath(), df_one_hot: OutputPath()):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    df_churn = pd.read_csv(df_churn_ip)\n",
    "    empty_cols = ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "           'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "           'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport',\n",
    "           'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "           'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
    "\n",
    "    for i in empty_cols:\n",
    "        df_churn[i]=df_churn[i].replace(\" \",np.nan)\n",
    "\n",
    "    df_churn.drop(['customerID'], axis=1, inplace=True)\n",
    "    df_churn = df_churn.dropna()\n",
    "    binary_cols = ['Partner','Dependents','PhoneService','PaperlessBilling']\n",
    "\n",
    "    for i in binary_cols:\n",
    "        df_churn[i] = df_churn[i].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "    #Encoding column 'gender'\n",
    "    df_churn['gender'] = df_churn['gender'].replace({\"Male\":1,\"Female\":0})\n",
    "\n",
    "\n",
    "    category_cols = ['PaymentMethod','MultipleLines','InternetService','OnlineSecurity',\n",
    "                   'OnlineBackup','DeviceProtection',\n",
    "                   'TechSupport','StreamingTV','StreamingMovies','Contract']\n",
    "\n",
    "    for cc in category_cols:\n",
    "        dummies = pd.get_dummies(df_churn[cc], drop_first=False)\n",
    "        dummies = dummies.add_prefix(\"{}#\".format(cc))\n",
    "        df_churn.drop(cc, axis=1, inplace=True)\n",
    "        df_churn = df_churn.join(dummies)\n",
    "\n",
    "    df_churn['Churn'] = df_churn['Churn'].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "    df_churn.to_csv(df_one_hot, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_one_hot_encode = kfp.components.func_to_container_op(func = one_hot_encode, \n",
    "                                                          output_component_file = './one-hot-encode-func.yaml',\n",
    "                                                          packages_to_install = ['scikit-learn==0.22.2','numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3',\n",
    "                                                                                 'imbalanced-learn==0.6.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "\n",
    "def rf_model(df_churn_ip: InputPath(), n_estimators: int, conf_matr: OutputPath(), metadata_out: OutputPath(),\n",
    "             metrics_out: OutputPath()):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    df_churn = pd.read_csv(df_churn_ip)\n",
    "    \n",
    "    df_churn.dropna(inplace=True)\n",
    "    n_est = n_estimators\n",
    "\n",
    "    y1 = df_churn['Churn']\n",
    "    X1 = df_churn.drop(['Churn'],axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)\n",
    "    rfc_best = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 50, max_depth=8,\n",
    "                                    criterion='gini')\n",
    "\n",
    "    rfc_best.fit(X_train, y_train) \n",
    "    y_test_pred = rfc_best.predict(X_test)\n",
    "    rf_score = rfc_best.score(X_test, y_test)\n",
    "    conf = confusion_matrix(y_test, y_test_pred)\n",
    "    print(conf)\n",
    "\n",
    "    #code to generate artifacts\n",
    "\n",
    "    vocab = list(y_test.unique())\n",
    "    cm = confusion_matrix(y_test, y_test_pred, labels=vocab)\n",
    "    data = []\n",
    "    for target_index, target_row in enumerate(cm):\n",
    "        for predicted_index, count in enumerate(target_row):\n",
    "            data.append((vocab[target_index], vocab[predicted_index], count))\n",
    "\n",
    "    df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n",
    "    print(df_cm)\n",
    "    df_cm.to_csv(conf_matr, columns=['target', 'predicted', 'count'], header=False, index=False)\n",
    "\n",
    "    #df_cm.to_csv(\"gs://mlopstest/confusionmatrix.csv\", index=False)\n",
    "    \n",
    "    cm_file = os.path.join(args.output, 'confusion_matrix.csv')\n",
    "    with file_io.FileIO(cm_file, 'w') as f:\n",
    "        df_cm.to_csv(f, columns=['target', 'predicted', 'count'], header=False, index=False)\n",
    "\n",
    "    metadata = {\n",
    "    'outputs' : [{\n",
    "      'type': 'confusion_matrix',\n",
    "      'format': 'csv',\n",
    "      'schema': [\n",
    "        {'name': 'target', 'type': 'CATEGORY'},\n",
    "        {'name': 'predicted', 'type': 'CATEGORY'},\n",
    "        {'name': 'count', 'type': 'NUMBER'},\n",
    "      ],\n",
    "      'source': conf_matr,\n",
    "      # Convert vocab to string because for bealean values we want \"True|False\" to match csv data.\n",
    "      'labels': list(map(str, vocab)),\n",
    "    }]\n",
    "    }\n",
    "    \n",
    "    with open(metadata_out, 'w+') as f1:\n",
    "        json.dump(metadata, f1)\n",
    "\n",
    "    #json.dump(metadata, metadata_out)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    metrics = {\n",
    "    'metrics': [{\n",
    "      'name': 'accuracy-score',\n",
    "      'numberValue':  accuracy,\n",
    "      'format': \"PERCENTAGE\",\n",
    "    }]\n",
    "    }\n",
    "    #with file_io.FileIO('/mlpipeline-metrics.json', 'w') as f:\n",
    "    with open(metrics_out, 'w+') as f:\n",
    "        json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_rf_model = kfp.components.func_to_container_op(func = rf_model, \n",
    "                                                          output_component_file = './rf-model-func.yaml', \n",
    "                                                   packages_to_install = ['scikit-learn==0.22.2','numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3',\n",
    "                                                                                 'imbalanced-learn==0.6.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A program to generate ROC data out of prediction results.\n",
    "# Usage:\n",
    "# python roc.py  \\\n",
    "#   --predictions=gs://bradley-playground/sfpd/predictions/part-* \\\n",
    "#   --trueclass=ACTION \\\n",
    "#   --output=gs://bradley-playground/sfpd/roc/ \\\n",
    "\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    parser = argparse.ArgumentParser(description='ML Trainer')\n",
    "    parser.add_argument('--predictions', type=str, help='GCS path of prediction file pattern.')\n",
    "    parser.add_argument('--trueclass', type=str, default='true',\n",
    "                      help='The name of the class as true value. If missing, assuming it is ' +\n",
    "                           'binary classification and default to \"true\".')\n",
    "    parser.add_argument('--true_score_column', type=str, default='true',\n",
    "                      help='The name of the column for positive prob. If missing, assuming it is ' +\n",
    "                           'binary classification and defaults to \"true\".')\n",
    "    parser.add_argument('--target_lambda', type=str,\n",
    "                      help='a lambda function as a string to determine positive or negative.' +\n",
    "                           'For example, \"lambda x: x[\\'a\\'] and x[\\'b\\']\". If missing, ' +\n",
    "                           'input must have a \"target\" column.')\n",
    "    parser.add_argument('--output', type=str, help='GCS path of the output directory.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    storage_service_scheme = urlparse.urlparse(args.output).scheme\n",
    "    on_cloud = True if storage_service_scheme else False\n",
    "    \n",
    "    if not on_cloud and not os.path.exists(args.output):\n",
    "        os.makedirs(args.output)\n",
    "\n",
    "    schema_file = os.path.join(os.path.dirname(args.predictions), 'schema.json')\n",
    "    schema = json.loads(file_io.read_file_to_string(schema_file))\n",
    "    names = [x['name'] for x in schema]\n",
    "\n",
    "    if not args.target_lambda and 'target' not in names:\n",
    "        raise ValueError('There is no \"target\" column, and target_lambda is not provided.')\n",
    "\n",
    "    if args.true_score_column not in names:\n",
    "        raise ValueError('Cannot find column name \"%s\"' % args.true_score_column)\n",
    "\n",
    "    dfs = []\n",
    "    files = file_io.get_matching_files(args.predictions)\n",
    "    \n",
    "    for file in files:\n",
    "        with file_io.FileIO(file, 'r') as f:\n",
    "            dfs.append(pd.read_csv(f, names=names))\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    \n",
    "    if args.target_lambda:\n",
    "        df['target'] = df.apply(eval(args.target_lambda), axis=1)\n",
    "    else:\n",
    "        df['target'] = df['target'].apply(lambda x: 1 if x == args.trueclass else 0)\n",
    "    \n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(df['target'], df[args.true_score_column])\n",
    "    roc_auc = roc_auc_score(df['target'], df[args.true_score_column])\n",
    "    df_roc = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds})\n",
    "    roc_file = os.path.join(args.output, 'roc.csv')\n",
    "    \n",
    "    with file_io.FileIO(roc_file, 'w') as f:\n",
    "        df_roc.to_csv(f, columns=['fpr', 'tpr', 'thresholds'], header=False, index=False)\n",
    "\n",
    "    metadata = {\n",
    "    'outputs': [{\n",
    "      'type': 'roc',\n",
    "      'format': 'csv',\n",
    "      'schema': [\n",
    "        {'name': 'fpr', 'type': 'NUMBER'},\n",
    "        {'name': 'tpr', 'type': 'NUMBER'},\n",
    "        {'name': 'thresholds', 'type': 'NUMBER'},\n",
    "      ],\n",
    "      'source': roc_file\n",
    "    }]\n",
    "    }\n",
    "    \n",
    "    with file_io.FileIO('/mlpipeline-ui-metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    metrics = {\n",
    "    'metrics': [{\n",
    "      'name': 'roc-auc-score',\n",
    "      'numberValue':  roc_auc,\n",
    "    }]\n",
    "    }\n",
    "    \n",
    "    with file_io.FileIO('/mlpipeline-metrics.json', 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A program to generate confusion matrix data out of prediction results.\n",
    "# Usage:\n",
    "# python confusion_matrix.py  \\\n",
    "#   --predictions=gs://bradley-playground/sfpd/predictions/part-* \\\n",
    "#   --output=gs://bradley-playground/sfpd/cm/ \\\n",
    "#   --target=resolution \\\n",
    "#   --analysis=gs://bradley-playground/sfpd/analysis \\\n",
    "\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import urlparse\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='ML Trainer')\n",
    "    parser.add_argument('--predictions', type=str, help='GCS path of prediction file pattern.')\n",
    "    parser.add_argument('--output', type=str, help='GCS path of the output directory.')\n",
    "    parser.add_argument('--target_lambda', type=str,\n",
    "                      help='a lambda function as a string to compute target.' +\n",
    "                           'For example, \"lambda x: x[\\'a\\'] + x[\\'b\\']\"' +\n",
    "                           'If not set, the input must include a \"target\" column.')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    storage_service_scheme = urlparse.urlparse(args.output).scheme\n",
    "    on_cloud = True if storage_service_scheme else False\n",
    "    \n",
    "    if not on_cloud and not os.path.exists(args.output):\n",
    "        os.makedirs(args.output)\n",
    "\n",
    "    schema_file = os.path.join(os.path.dirname(args.predictions), 'schema.json')\n",
    "    schema = json.loads(file_io.read_file_to_string(schema_file))\n",
    "    names = [x['name'] for x in schema]\n",
    "    dfs = []\n",
    "    files = file_io.get_matching_files(args.predictions)\n",
    "    \n",
    "    for file in files:\n",
    "        with file_io.FileIO(file, 'r') as f:\n",
    "            dfs.append(pd.read_csv(f, names=names))\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    \n",
    "    if args.target_lambda:\n",
    "        df['target'] = df.apply(eval(args.target_lambda), axis=1)\n",
    "\n",
    "    vocab = list(df['target'].unique())\n",
    "    cm = confusion_matrix(df['target'], df['predicted'], labels=vocab)\n",
    "    data = []\n",
    "    \n",
    "    for target_index, target_row in enumerate(cm):\n",
    "        for predicted_index, count in enumerate(target_row):\n",
    "            data.append((vocab[target_index], vocab[predicted_index], count))\n",
    "\n",
    "    df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n",
    "    cm_file = os.path.join(args.output, 'confusion_matrix.csv')\n",
    "    \n",
    "    with file_io.FileIO(cm_file, 'w') as f:\n",
    "        df_cm.to_csv(f, columns=['target', 'predicted', 'count'], header=False, index=False)\n",
    "\n",
    "    metadata = {\n",
    "    'outputs' : [{\n",
    "      'type': 'confusion_matrix',\n",
    "      'format': 'csv',\n",
    "      'schema': [\n",
    "        {'name': 'target', 'type': 'CATEGORY'},\n",
    "        {'name': 'predicted', 'type': 'CATEGORY'},\n",
    "        {'name': 'count', 'type': 'NUMBER'},\n",
    "      ],\n",
    "      'source': cm_file,\n",
    "      # Convert vocab to string because for bealean values we want \"True|False\" to match csv data.\n",
    "      'labels': list(map(str, vocab)),\n",
    "    }]\n",
    "    }\n",
    "    \n",
    "    with file_io.FileIO('/mlpipeline-ui-metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    accuracy = accuracy_score(df['target'], df['predicted'])\n",
    "    metrics = {\n",
    "    'metrics': [{\n",
    "      'name': 'accuracy-score',\n",
    "      'numberValue':  accuracy,\n",
    "      'format': \"PERCENTAGE\",\n",
    "    }]\n",
    "    }\n",
    "    \n",
    "    with file_io.FileIO('/mlpipeline-metrics.json', 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def xgb_model(df_churn_ip: InputPath(), n_estimators: int):\n",
    "        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import xgboost as xgb\n",
    "\n",
    "    df_churn = pd.read_csv(df_churn_ip)\n",
    "    df_churn.dropna(inplace=True)\n",
    "    n_est = n_estimators\n",
    "\n",
    "    y1 = df_churn['Churn']\n",
    "    X1 = df_churn.drop(['Churn'],axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)\n",
    "\n",
    "\n",
    "    sm = SMOTE(random_state=0)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    X_test_res, y_test_res = sm.fit_sample(X_test, y_test)\n",
    "\n",
    "    clfxg = xgb.XGBClassifier(objective='binary:logistic', verbosity=0, max_depth=2, eta = 1, silent=0)\n",
    "    clfxg.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    y_test_pred = clfxg.predict(X_test_res)\n",
    "    conf = confusion_matrix(y_test_res, y_test_pred)\n",
    "    print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_xgb_model = kfp.components.func_to_container_op(func = xgb_model, \n",
    "                                                          output_component_file = './xgb-model-func.yaml',\n",
    "                                                          packages_to_install = ['scikit-learn==0.22.2','numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3',\n",
    "                                                                                 'imbalanced-learn==0.6.2','xgboost==1.0.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "\n",
    "@dsl.pipeline(name='ML Pipeline',description='Churn predictions using Random Forest and XG Boost Algorithms')\n",
    "def TChurn_func(f_n = \"https://raw.githubusercontent.com/rujual/telco_churn_pipeline/master/Data1.csv\", \n",
    "                n_estimators = 100):\n",
    "    \n",
    "    #Passing pipeline parameter and a constant value as operation arguments\n",
    "    read_data_task = kfp_read_data(file_name = f_n) \n",
    "    ohe_task = kfp_one_hot_encode(read_data_task.outputs['df_churn_op'])\n",
    "    rf_model_task = kfp_rf_model(ohe_task.outputs['df_one_hot'], n_estimators)\n",
    "    xgb_model_task = kfp_xgb_model(ohe_task.outputs['df_one_hot'], n_estimators)\n",
    "\n",
    "#For an operation with a single return value, the output reference can be accessed using `task.output` or `task.outputs['output_name']` syntax\n",
    "#For an operation with a multiple return values, the output references can be accessed using `task.outputs['output_name']` syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruju/anaconda3/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"100\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    }
   ],
   "source": [
    "pipeline_func = TChurn_func\n",
    "pipeline_filename = pipeline_func.__name__+'.pipeline.tar.gz'\n",
    "\n",
    "import kfp.compiler as comp\n",
    "comp.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
