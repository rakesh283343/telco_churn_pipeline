{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook using kfp.create_component_from_func function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05M92t4L_U51"
   },
   "source": [
    "### Telco Churn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05M92t4L_U51"
   },
   "outputs": [],
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "import kfp\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zfou2iW5_U6C"
   },
   "outputs": [],
   "source": [
    "## Read Data\n",
    "\n",
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def read_data(file_name: str) -> str: \n",
    "        \n",
    "    ## Import Required Libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    #This line may cause problems as file is on the system and not inside container\n",
    "    #Importing directly from Github Raw Content\n",
    "    df_churn = pd.read_csv(file_name)\n",
    "    df_churn = df_churn.astype(str)\n",
    "    \n",
    "    def remove_spaces(s):\n",
    "        return s.replace(' ','_')\n",
    "    \n",
    "    df_churn = df_churn.applymap(remove_spaces)\n",
    "    \n",
    "    #returning df as to_csv without passing path converts it to string\n",
    "    df_str = df_churn.to_string(index=False)\n",
    "    return df_str #to_dict() #to_csv(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohRWvYOQ_U6H"
   },
   "outputs": [],
   "source": [
    "kfp_read_data = kfp.components.create_component_from_func(func = read_data, \n",
    "                                                          output_component_file = './read-data-func.yaml',\n",
    "                                                          packages_to_install = ['numpy','pandas'])\n",
    "\n",
    "read_data_task = kfp_read_data(file_name = 'https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0amunpu_U6N"
   },
   "outputs": [],
   "source": [
    "## One-Hot-Encode\n",
    "\n",
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def one_hot_encode(input_df: str) -> str: \n",
    "\n",
    "    ## Import Required Libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    lines = input_df.splitlines()\n",
    "    l_df = []\n",
    "    for l in lines:\n",
    "        l_df.append(l.split())\n",
    "        \n",
    "    cols = l_df[0]\n",
    "    l_df = l_df[1:]\n",
    "    df_churn = pd.DataFrame(l_df, columns=cols) \n",
    "\n",
    "    empty_cols=['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "           'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "           'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport',\n",
    "           'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "           'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
    "\n",
    "    for i in empty_cols:\n",
    "        df_churn[i]=df_churn[i].replace(\" \",np.nan)\n",
    "\n",
    "    df_churn.drop(['customerID','cluster_number'], axis=1, inplace=True)\n",
    "    df_churn = df_churn.dropna()\n",
    "    binary_cols = ['Partner','Dependents','PhoneService','PaperlessBilling']\n",
    "\n",
    "    for i in binary_cols:\n",
    "        df_churn[i] = df_churn[i].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "    #Encoding column 'gender'\n",
    "    df_churn['gender'] = df_churn['gender'].replace({\"Male\":1,\"Female\":0})\n",
    "\n",
    "\n",
    "    category_cols = ['PaymentMethod','MultipleLines','InternetService','OnlineSecurity',\n",
    "                   'OnlineBackup','DeviceProtection',\n",
    "                   'TechSupport','StreamingTV','StreamingMovies','Contract']\n",
    "\n",
    "    for cc in category_cols:\n",
    "        dummies = pd.get_dummies(df_churn[cc], drop_first=False)\n",
    "        dummies = dummies.add_prefix(\"{}#\".format(cc))\n",
    "        df_churn.drop(cc, axis=1, inplace=True)\n",
    "        df_churn = df_churn.join(dummies)\n",
    "\n",
    "    df_churn['Churn'] = df_churn['Churn'].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "    #saving files may need a PV allocation to container\n",
    "    #output of files as Named tuple may cause problems \n",
    "    \n",
    "    df_str = df_churn.to_string(index=False)\n",
    "    return df_str #to_dict() #to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x3HCxWyE_U6S"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to serialize the value \"OrderedDict([('Output', TaskOutputArgument(task_output=TaskOutputReference(output_name='Output', task_id=None, task=TaskSpec(component_ref=ComponentReference(name=None, digest=None, tag=None, url=None, spec=ComponentSpec(name='Read data', description=None, metadata=None, inputs=[InputSpec(name='file_name', type='String', description=None, default=None, optional=False)], outputs=[OutputSpec(name='Output', type='String', description=None)], implementation=ContainerImplementation(container=ContainerSpec(image='tensorflow/tensorflow:1.13.2-py3', command=['sh', '-c', '(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' --user) && \"$0\" \"$@\"', 'python3', '-u', '-c', 'def read_data(file_name )  : \\n\\n    ## Import Required Libraries\\n    import pandas as pd\\n    import numpy as np\\n\\n    #This line may cause problems as file is on the system and not inside container\\n    #Importing directly from Github Raw Content\\n    df_churn = pd.read_csv(file_name)\\n    df_churn = df_churn.astype(str)\\n\\n    def remove_spaces(s):\\n        return s.replace(\\' \\',\\'_\\')\\n\\n    df_churn = df_churn.applymap(remove_spaces)\\n\\n    #returning df as to_csv without passing path converts it to string\\n    df_str = df_churn.to_string(index=False)\\n    return df_str #to_dict() #to_csv(index=False)\\n\\ndef _serialize_str(str_value: str) -> str:\\n    if not isinstance(str_value, str):\\n        raise TypeError(\\'Value \"{}\" has type \"{}\" instead of str.\\'.format(str(str_value), str(type(str_value))))\\n    return str_value\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=\\'Read data\\', description=\\'\\')\\n_parser.add_argument(\"--file-name\", dest=\"file_name\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\\n_parsed_args = vars(_parser.parse_args())\\n_output_files = _parsed_args.pop(\"_output_paths\", [])\\n\\n_outputs = read_data(**_parsed_args)\\n\\nif not hasattr(_outputs, \\'__getitem__\\') or isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\n_output_serializers = [\\n    _serialize_str,\\n\\n]\\n\\nimport os\\nfor idx, output_file in enumerate(_output_files):\\n    try:\\n        os.makedirs(os.path.dirname(output_file))\\n    except OSError:\\n        pass\\n    with open(output_file, \\'w\\') as f:\\n        f.write(_output_serializers[idx](_outputs[idx]))\\n'], args=['--file-name', InputValuePlaceholder(input_name='file_name'), '----output-paths', OutputPathPlaceholder(output_name='Output')], env=None, file_outputs=None)), version='google.com/cloud/pipelines/component/v1')), arguments={'file_name': 'https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv'}, is_enabled=None, execution_options=None), type='String')))])\" of type \"OrderedDict\" to type \"String\". Exception: Value \"OrderedDict([('Output', TaskOutputArgument(task_output=TaskOutputReference(output_name='Output', task_id=None, task=TaskSpec(component_ref=ComponentReference(name=None, digest=None, tag=None, url=None, spec=ComponentSpec(name='Read data', description=None, metadata=None, inputs=[InputSpec(name='file_name', type='String', description=None, default=None, optional=False)], outputs=[OutputSpec(name='Output', type='String', description=None)], implementation=ContainerImplementation(container=ContainerSpec(image='tensorflow/tensorflow:1.13.2-py3', command=['sh', '-c', '(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' --user) && \"$0\" \"$@\"', 'python3', '-u', '-c', 'def read_data(file_name )  : \\n\\n    ## Import Required Libraries\\n    import pandas as pd\\n    import numpy as np\\n\\n    #This line may cause problems as file is on the system and not inside container\\n    #Importing directly from Github Raw Content\\n    df_churn = pd.read_csv(file_name)\\n    df_churn = df_churn.astype(str)\\n\\n    def remove_spaces(s):\\n        return s.replace(\\' \\',\\'_\\')\\n\\n    df_churn = df_churn.applymap(remove_spaces)\\n\\n    #returning df as to_csv without passing path converts it to string\\n    df_str = df_churn.to_string(index=False)\\n    return df_str #to_dict() #to_csv(index=False)\\n\\ndef _serialize_str(str_value: str) -> str:\\n    if not isinstance(str_value, str):\\n        raise TypeError(\\'Value \"{}\" has type \"{}\" instead of str.\\'.format(str(str_value), str(type(str_value))))\\n    return str_value\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=\\'Read data\\', description=\\'\\')\\n_parser.add_argument(\"--file-name\", dest=\"file_name\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\\n_parsed_args = vars(_parser.parse_args())\\n_output_files = _parsed_args.pop(\"_output_paths\", [])\\n\\n_outputs = read_data(**_parsed_args)\\n\\nif not hasattr(_outputs, \\'__getitem__\\') or isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\n_output_serializers = [\\n    _serialize_str,\\n\\n]\\n\\nimport os\\nfor idx, output_file in enumerate(_output_files):\\n    try:\\n        os.makedirs(os.path.dirname(output_file))\\n    except OSError:\\n        pass\\n    with open(output_file, \\'w\\') as f:\\n        f.write(_output_serializers[idx](_outputs[idx]))\\n'], args=['--file-name', InputValuePlaceholder(input_name='file_name'), '----output-paths', OutputPathPlaceholder(output_name='Output')], env=None, file_outputs=None)), version='google.com/cloud/pipelines/component/v1')), arguments={'file_name': 'https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv'}, is_enabled=None, execution_options=None), type='String')))])\" has type \"<class 'collections.OrderedDict'>\" instead of str.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/kfp/components/_data_passing.py\u001b[0m in \u001b[0;36mserialize_value\u001b[0;34m(value, type_name)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mserialized_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/kfp/components/_data_passing.py\u001b[0m in \u001b[0;36m_serialize_str\u001b[0;34m(str_value)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Value \"{}\" has type \"{}\" instead of str.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Value \"OrderedDict([('Output', TaskOutputArgument(task_output=TaskOutputReference(output_name='Output', task_id=None, task=TaskSpec(component_ref=ComponentReference(name=None, digest=None, tag=None, url=None, spec=ComponentSpec(name='Read data', description=None, metadata=None, inputs=[InputSpec(name='file_name', type='String', description=None, default=None, optional=False)], outputs=[OutputSpec(name='Output', type='String', description=None)], implementation=ContainerImplementation(container=ContainerSpec(image='tensorflow/tensorflow:1.13.2-py3', command=['sh', '-c', '(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' --user) && \"$0\" \"$@\"', 'python3', '-u', '-c', 'def read_data(file_name )  : \\n\\n    ## Import Required Libraries\\n    import pandas as pd\\n    import numpy as np\\n\\n    #This line may cause problems as file is on the system and not inside container\\n    #Importing directly from Github Raw Content\\n    df_churn = pd.read_csv(file_name)\\n    df_churn = df_churn.astype(str)\\n\\n    def remove_spaces(s):\\n        return s.replace(\\' \\',\\'_\\')\\n\\n    df_churn = df_churn.applymap(remove_spaces)\\n\\n    #returning df as to_csv without passing path converts it to string\\n    df_str = df_churn.to_string(index=False)\\n    return df_str #to_dict() #to_csv(index=False)\\n\\ndef _serialize_str(str_value: str) -> str:\\n    if not isinstance(str_value, str):\\n        raise TypeError(\\'Value \"{}\" has type \"{}\" instead of str.\\'.format(str(str_value), str(type(str_value))))\\n    return str_value\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=\\'Read data\\', description=\\'\\')\\n_parser.add_argument(\"--file-name\", dest=\"file_name\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\\n_parsed_args = vars(_parser.parse_args())\\n_output_files = _parsed_args.pop(\"_output_paths\", [])\\n\\n_outputs = read_data(**_parsed_args)\\n\\nif not hasattr(_outputs, \\'__getitem__\\') or isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\n_output_serializers = [\\n    _serialize_str,\\n\\n]\\n\\nimport os\\nfor idx, output_file in enumerate(_output_files):\\n    try:\\n        os.makedirs(os.path.dirname(output_file))\\n    except OSError:\\n        pass\\n    with open(output_file, \\'w\\') as f:\\n        f.write(_output_serializers[idx](_outputs[idx]))\\n'], args=['--file-name', InputValuePlaceholder(input_name='file_name'), '----output-paths', OutputPathPlaceholder(output_name='Output')], env=None, file_outputs=None)), version='google.com/cloud/pipelines/component/v1')), arguments={'file_name': 'https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv'}, is_enabled=None, execution_options=None), type='String')))])\" has type \"<class 'collections.OrderedDict'>\" instead of str.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-37bba2bb9450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                                           \u001b[0moutput_component_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./one-hot-encode-func.yaml'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                           packages_to_install = ['numpy','pandas'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mone_hot_encode_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfp_one_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_data_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/kfp/components/_dynamic.py\u001b[0m in \u001b[0;36mOne hot encode\u001b[0;34m(input_df)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpass_locals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: F821 TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpass_locals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__code__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/kfp/components/_components.py\u001b[0m in \u001b[0;36mcreate_task_from_component_and_arguments\u001b[0;34m(pythonic_arguments)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mcomponent_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         )\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/kfp/components/_components.py\u001b[0m in \u001b[0;36m_create_task_spec_from_component_and_arguments\u001b[0;34m(component_spec, arguments, component_ref)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# argument_value is a constant value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mserialized_argument_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margument_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mtask_arguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialized_argument_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/kfp/components/_data_passing.py\u001b[0m in \u001b[0;36mserialize_value\u001b[0;34m(value, type_name)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             ))\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to serialize the value \"OrderedDict([('Output', TaskOutputArgument(task_output=TaskOutputReference(output_name='Output', task_id=None, task=TaskSpec(component_ref=ComponentReference(name=None, digest=None, tag=None, url=None, spec=ComponentSpec(name='Read data', description=None, metadata=None, inputs=[InputSpec(name='file_name', type='String', description=None, default=None, optional=False)], outputs=[OutputSpec(name='Output', type='String', description=None)], implementation=ContainerImplementation(container=ContainerSpec(image='tensorflow/tensorflow:1.13.2-py3', command=['sh', '-c', '(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' --user) && \"$0\" \"$@\"', 'python3', '-u', '-c', 'def read_data(file_name )  : \\n\\n    ## Import Required Libraries\\n    import pandas as pd\\n    import numpy as np\\n\\n    #This line may cause problems as file is on the system and not inside container\\n    #Importing directly from Github Raw Content\\n    df_churn = pd.read_csv(file_name)\\n    df_churn = df_churn.astype(str)\\n\\n    def remove_spaces(s):\\n        return s.replace(\\' \\',\\'_\\')\\n\\n    df_churn = df_churn.applymap(remove_spaces)\\n\\n    #returning df as to_csv without passing path converts it to string\\n    df_str = df_churn.to_string(index=False)\\n    return df_str #to_dict() #to_csv(index=False)\\n\\ndef _serialize_str(str_value: str) -> str:\\n    if not isinstance(str_value, str):\\n        raise TypeError(\\'Value \"{}\" has type \"{}\" instead of str.\\'.format(str(str_value), str(type(str_value))))\\n    return str_value\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=\\'Read data\\', description=\\'\\')\\n_parser.add_argument(\"--file-name\", dest=\"file_name\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\\n_parsed_args = vars(_parser.parse_args())\\n_output_files = _parsed_args.pop(\"_output_paths\", [])\\n\\n_outputs = read_data(**_parsed_args)\\n\\nif not hasattr(_outputs, \\'__getitem__\\') or isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\n_output_serializers = [\\n    _serialize_str,\\n\\n]\\n\\nimport os\\nfor idx, output_file in enumerate(_output_files):\\n    try:\\n        os.makedirs(os.path.dirname(output_file))\\n    except OSError:\\n        pass\\n    with open(output_file, \\'w\\') as f:\\n        f.write(_output_serializers[idx](_outputs[idx]))\\n'], args=['--file-name', InputValuePlaceholder(input_name='file_name'), '----output-paths', OutputPathPlaceholder(output_name='Output')], env=None, file_outputs=None)), version='google.com/cloud/pipelines/component/v1')), arguments={'file_name': 'https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv'}, is_enabled=None, execution_options=None), type='String')))])\" of type \"OrderedDict\" to type \"String\". Exception: Value \"OrderedDict([('Output', TaskOutputArgument(task_output=TaskOutputReference(output_name='Output', task_id=None, task=TaskSpec(component_ref=ComponentReference(name=None, digest=None, tag=None, url=None, spec=ComponentSpec(name='Read data', description=None, metadata=None, inputs=[InputSpec(name='file_name', type='String', description=None, default=None, optional=False)], outputs=[OutputSpec(name='Output', type='String', description=None)], implementation=ContainerImplementation(container=ContainerSpec(image='tensorflow/tensorflow:1.13.2-py3', command=['sh', '-c', '(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'numpy\\' \\'pandas\\' --user) && \"$0\" \"$@\"', 'python3', '-u', '-c', 'def read_data(file_name )  : \\n\\n    ## Import Required Libraries\\n    import pandas as pd\\n    import numpy as np\\n\\n    #This line may cause problems as file is on the system and not inside container\\n    #Importing directly from Github Raw Content\\n    df_churn = pd.read_csv(file_name)\\n    df_churn = df_churn.astype(str)\\n\\n    def remove_spaces(s):\\n        return s.replace(\\' \\',\\'_\\')\\n\\n    df_churn = df_churn.applymap(remove_spaces)\\n\\n    #returning df as to_csv without passing path converts it to string\\n    df_str = df_churn.to_string(index=False)\\n    return df_str #to_dict() #to_csv(index=False)\\n\\ndef _serialize_str(str_value: str) -> str:\\n    if not isinstance(str_value, str):\\n        raise TypeError(\\'Value \"{}\" has type \"{}\" instead of str.\\'.format(str(str_value), str(type(str_value))))\\n    return str_value\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=\\'Read data\\', description=\\'\\')\\n_parser.add_argument(\"--file-name\", dest=\"file_name\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\\n_parsed_args = vars(_parser.parse_args())\\n_output_files = _parsed_args.pop(\"_output_paths\", [])\\n\\n_outputs = read_data(**_parsed_args)\\n\\nif not hasattr(_outputs, \\'__getitem__\\') or isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\n_output_serializers = [\\n    _serialize_str,\\n\\n]\\n\\nimport os\\nfor idx, output_file in enumerate(_output_files):\\n    try:\\n        os.makedirs(os.path.dirname(output_file))\\n    except OSError:\\n        pass\\n    with open(output_file, \\'w\\') as f:\\n        f.write(_output_serializers[idx](_outputs[idx]))\\n'], args=['--file-name', InputValuePlaceholder(input_name='file_name'), '----output-paths', OutputPathPlaceholder(output_name='Output')], env=None, file_outputs=None)), version='google.com/cloud/pipelines/component/v1')), arguments={'file_name': 'https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv'}, is_enabled=None, execution_options=None), type='String')))])\" has type \"<class 'collections.OrderedDict'>\" instead of str."
     ]
    }
   ],
   "source": [
    "kfp_one_hot_encode = kfp.components.create_component_from_func(func = one_hot_encode, \n",
    "                                                          output_component_file = './one-hot-encode-func.yaml',\n",
    "                                                          packages_to_install = ['numpy','pandas'])\n",
    "one_hot_encode_task = kfp_one_hot_encode(read_data_task.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHhL-J_X_U6Y"
   },
   "outputs": [],
   "source": [
    "## Random Forest Model\n",
    "from typing import NamedTuple\n",
    "def rf_model(input_df: dict, n_estimators: int = 100) -> NamedTuple('Outputs', [('Cf1', int), ('Cf2', int),\n",
    "                                                                                     ('Cf3', int), ('Cf4', int)]):\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    \n",
    "    lines = input_df.splitlines()\n",
    "    l_df = []\n",
    "    for l in lines:\n",
    "        l_df.append(l.split())\n",
    "        \n",
    "    cols = l_df[0]\n",
    "    l_df = l_df[1:]\n",
    "    df_churn = pd.DataFrame(l_df, columns=cols) \n",
    "    \n",
    "    n_estimators = 100\n",
    "    n_est = n_estimators\n",
    "\n",
    "    y1 = df_churn['Churn']\n",
    "    X1 = df_churn.drop(['Churn'],axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)\n",
    "\n",
    "    sm = SMOTE(random_state=0)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth' : [2,4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "\n",
    "    rfc=RandomForestClassifier(random_state=42,n_estimators=n_est)\n",
    "    gsv_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "    rfc.fit(X_train_res, y_train_res)\n",
    "\n",
    "    rfc_best=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 50, max_depth=8,\n",
    "                                    criterion='gini')\n",
    "\n",
    "    rfc_best.fit(X_train_res, y_train_res)\n",
    "    X_test_res, y_test_res = sm.fit_sample(X_test, y_test)\n",
    "    y_test_pred = rfc_best.predict(X_test_res)\n",
    "    rf_score = rfc_best.score(X_test_res, y_test_res)\n",
    "    conf = confusion_matrix(y_test_res, y_test_pred)\n",
    "    \n",
    "    return (conf[0][0],conf[0][1],conf[1][0],conf[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HfsLs9l_U6i"
   },
   "outputs": [],
   "source": [
    "kfp_rf_model = kfp.components.create_component_from_func(func = rf_model, \n",
    "                                                          output_component_file = './rf-model-func.yaml',\n",
    "                                                          packages_to_install = ['scikit-learn==0.19.1','numpy','pandas','imbalanced-learn==0.6.2'])\n",
    "rf_model_task = kfp_rf_model(one_hot_encode_task.outputs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the components into pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PQNawQS_U6n"
   },
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "\n",
    "@dsl.pipeline(name='Merchant-Churn-Pipeline',description='A pipeline that processes and performs ML-Predictions using Random Forest Algorithm')\n",
    "def Merch_Churn(file_name = \"https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv\", \n",
    "                n_estimators = 100):\n",
    "    \n",
    "    #Passing pipeline parameter and a constant value as operation arguments\n",
    "    #Passing a task output reference as operation arguments\n",
    "    \n",
    "    read_data_task = kfp_read_data(file_name)    #Returns a dsl.ContainerOp class instance. \n",
    "    one_hot_encode_task = kfp_one_hot_encode(read_data_task.output) \n",
    "    rf_model_task = kfp_rf_model(one_hot_encode_task.output, n_estimators = 100)\n",
    "    \n",
    "\n",
    "#For an operation with a single return value, the output reference can be accessed using `task.output` or `task.outputs['output_name']` syntax\n",
    "#For an operation with a multiple return values, the output references can be accessed using `task.outputs['output_name']` syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXA3IA4Z_U6s"
   },
   "outputs": [],
   "source": [
    "pipeline_func = Merch_Churn\n",
    "pipeline_filename = pipeline_func.__name__+'.pipeline.tar.gz'\n",
    "\n",
    "import kfp.compiler as comp\n",
    "comp.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mc_final_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
