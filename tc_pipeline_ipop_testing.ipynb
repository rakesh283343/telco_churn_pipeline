{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_churn = pd.read_csv(\"https://raw.githubusercontent.com/rujual/telco_churn_pipeline/master/Data1.csv\")\n",
    "\n",
    "empty_cols = ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport',\n",
    "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
    "\n",
    "for i in empty_cols:\n",
    "    df_churn[i]=df_churn[i].replace(\" \",np.nan)\n",
    "\n",
    "df_churn.drop(['customerID'], axis=1, inplace=True)\n",
    "df_churn = df_churn.dropna()\n",
    "binary_cols = ['Partner','Dependents','PhoneService','PaperlessBilling']\n",
    "\n",
    "for i in binary_cols:\n",
    "    df_churn[i] = df_churn[i].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "#Encoding column 'gender'\n",
    "df_churn['gender'] = df_churn['gender'].replace({\"Male\":1,\"Female\":0})\n",
    "\n",
    "\n",
    "category_cols = ['PaymentMethod','MultipleLines','InternetService','OnlineSecurity',\n",
    "               'OnlineBackup','DeviceProtection',\n",
    "               'TechSupport','StreamingTV','StreamingMovies','Contract']\n",
    "\n",
    "for cc in category_cols:\n",
    "    dummies = pd.get_dummies(df_churn[cc], drop_first=False)\n",
    "    dummies = dummies.add_prefix(\"{}#\".format(cc))\n",
    "    df_churn.drop(cc, axis=1, inplace=True)\n",
    "    df_churn = df_churn.join(dummies)\n",
    "\n",
    "df_churn['Churn'] = df_churn['Churn'].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "import os\n",
    "\n",
    "df_churn.dropna(inplace=True)\n",
    "n_est = 100\n",
    "\n",
    "y1 = df_churn['Churn']\n",
    "X1 = df_churn.drop(['Churn'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)\n",
    "rfc_best=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 50, max_depth=8,\n",
    "                                criterion='gini')\n",
    "\n",
    "rfc_best.fit(X_train, y_train) \n",
    "y_test_pred = rfc_best.predict(X_test)\n",
    "rf_score = rfc_best.score(X_test, y_test)\n",
    "conf = confusion_matrix(y_test, y_test_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(y_test.unique())\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=vocab)\n",
    "data = []\n",
    "for target_index, target_row in enumerate(cm):\n",
    "    for predicted_index, count in enumerate(target_row):\n",
    "        data.append((vocab[target_index], vocab[predicted_index], count))\n",
    "\n",
    "df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm.to_csv('Conf_mat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    'outputs' : [{\n",
    "      'type': 'confusion_matrix',\n",
    "      'format': 'csv',\n",
    "      'schema': [\n",
    "        {'name': 'target', 'type': 'CATEGORY'},\n",
    "        {'name': 'predicted', 'type': 'CATEGORY'},\n",
    "        {'name': 'count', 'type': 'NUMBER'},\n",
    "      ],\n",
    "      'source': 'gs://mlopstest/Conf_mat.csv',\n",
    "      # Convert vocab to string because for bealean values we want \"True|False\" to match csv data.\n",
    "      'labels': list(map(str, vocab)),\n",
    "    }]\n",
    "  }\n",
    "with open('metadata.json', 'w') as f:#file_io.FileIO('metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "metadata = {\n",
    "'outputs' : [{\n",
    "  'type': 'confusion_matrix',\n",
    "  'format': 'csv',\n",
    "#   'schema': [\n",
    "#     {'name': 'target', 'type': 'CATEGORY'},\n",
    "#     {'name': 'predicted', 'type': 'CATEGORY'},\n",
    "#     {'name': 'count', 'type': 'NUMBER'},\n",
    "#   ],\n",
    "  'source': 'gs://mlopstest/Conf_mat.csv',\n",
    "  # Convert vocab to string because for bealean values we want \"True|False\" to match csv data.\n",
    "  #'labels': list(map(str, vocab)),\n",
    "}]\n",
    "}\n",
    "\n",
    "with open('metadata.json', 'w+') as f1:\n",
    "    json.dump(metadata, f1)\n",
    "\n",
    "#json.dump(metadata, metadata_out)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "metrics = {\n",
    "'metrics': [{\n",
    "  'name': 'accuracy-score',\n",
    "  'numberValue':  accuracy,\n",
    "  'format': \"PERCENTAGE\",\n",
    "}]\n",
    "}\n",
    "#with file_io.FileIO('/mlpipeline-metrics.json', 'w') as f:\n",
    "with open('metrics.json', 'w+') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\n",
    "# A program to generate ROC data out of prediction results.\n",
    "# Usage:\n",
    "# python roc.py  \\\n",
    "#   --predictions=gs://bradley-playground/sfpd/predictions/part-* \\\n",
    "#   --trueclass=ACTION \\\n",
    "#   --output=gs://bradley-playground/sfpd/roc/ \\\n",
    "\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    parser = argparse.ArgumentParser(description='ML Trainer')\n",
    "    parser.add_argument('--predictions', type=str, help='GCS path of prediction file pattern.')\n",
    "    parser.add_argument('--trueclass', type=str, default='true',\n",
    "                      help='The name of the class as true value. If missing, assuming it is ' +\n",
    "                           'binary classification and default to \"true\".')\n",
    "    parser.add_argument('--true_score_column', type=str, default='true',\n",
    "                      help='The name of the column for positive prob. If missing, assuming it is ' +\n",
    "                           'binary classification and defaults to \"true\".')\n",
    "    parser.add_argument('--target_lambda', type=str,\n",
    "                      help='a lambda function as a string to determine positive or negative.' +\n",
    "                           'For example, \"lambda x: x[\\'a\\'] and x[\\'b\\']\". If missing, ' +\n",
    "                           'input must have a \"target\" column.')\n",
    "    parser.add_argument('--output', type=str, help='GCS path of the output directory.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    storage_service_scheme = urlparse.urlparse(args.output).scheme\n",
    "    on_cloud = True if storage_service_scheme else False\n",
    "    \n",
    "    if not on_cloud and not os.path.exists(args.output):\n",
    "        os.makedirs(args.output)\n",
    "\n",
    "    schema_file = os.path.join(os.path.dirname(args.predictions), 'schema.json')\n",
    "    schema = json.loads(file_io.read_file_to_string(schema_file))\n",
    "    names = [x['name'] for x in schema]\n",
    "\n",
    "    if not args.target_lambda and 'target' not in names:\n",
    "        raise ValueError('There is no \"target\" column, and target_lambda is not provided.')\n",
    "\n",
    "    if args.true_score_column not in names:\n",
    "        raise ValueError('Cannot find column name \"%s\"' % args.true_score_column)\n",
    "\n",
    "    dfs = []\n",
    "    files = file_io.get_matching_files(args.predictions)\n",
    "    \n",
    "    for file in files:\n",
    "        with file_io.FileIO(file, 'r') as f:\n",
    "            dfs.append(pd.read_csv(f, names=names))\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    \n",
    "    if args.target_lambda:\n",
    "        df['target'] = df.apply(eval(args.target_lambda), axis=1)\n",
    "    else:\n",
    "        df['target'] = df['target'].apply(lambda x: 1 if x == args.trueclass else 0)\n",
    "    \n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(df['target'], df[args.true_score_column])\n",
    "    roc_auc = roc_auc_score(df['target'], df[args.true_score_column])\n",
    "    df_roc = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds})\n",
    "    roc_file = os.path.join(args.output, 'roc.csv')\n",
    "    \n",
    "    with file_io.FileIO(roc_file, 'w') as f:\n",
    "        df_roc.to_csv(f, columns=['fpr', 'tpr', 'thresholds'], header=False, index=False)\n",
    "\n",
    "    metadata = {\n",
    "    'outputs': [{\n",
    "      'type': 'roc',\n",
    "      'format': 'csv',\n",
    "      'schema': [\n",
    "        {'name': 'fpr', 'type': 'NUMBER'},\n",
    "        {'name': 'tpr', 'type': 'NUMBER'},\n",
    "        {'name': 'thresholds', 'type': 'NUMBER'},\n",
    "      ],\n",
    "      'source': roc_file\n",
    "    }]\n",
    "    }\n",
    "    \n",
    "    with file_io.FileIO('/mlpipeline-ui-metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    metrics = {\n",
    "    'metrics': [{\n",
    "      'name': 'roc-auc-score',\n",
    "      'numberValue':  roc_auc,\n",
    "    }]\n",
    "    }\n",
    "    \n",
    "    with file_io.FileIO('/mlpipeline-metrics.json', 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e477ea6f7dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# \"\"\"Uploads a file to the bucket.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstorage_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlopstest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google/cloud/storage/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project, credentials, _http, client_info, client_options)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         super(Client, self).__init__(\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_http\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_http\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         )\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google/cloud/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project, credentials, _http)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_http\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0m_ClientProjectMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_http\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_http\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google/cloud/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             raise EnvironmentError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google/cloud/client.py\u001b[0m in \u001b[0;36m_determine_default\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_determine_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;34m\"\"\"Helper:  use default project detection.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_determine_default_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google/cloud/_helpers.py\u001b[0m in \u001b[0;36m_determine_default_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \"\"\"\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google/auth/_default.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(scopes, request)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_project_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultCredentialsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_HELP_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started"
     ]
    }
   ],
   "source": [
    " # \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(mlopstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(source_file_name)\n",
    "\n",
    "print('File {} uploaded to {}.'.format(source_file_name, destination_blob_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to generate artifacts\n",
    "\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "vocab = list(y_test.unique())\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=vocab)\n",
    "data = []\n",
    "for target_index, target_row in enumerate(cm):\n",
    "    for predicted_index, count in enumerate(target_row):\n",
    "        data.append((vocab[target_index], vocab[predicted_index], count))\n",
    "\n",
    "df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n",
    "\n",
    "#df_cm.to_csv(conf_matr, columns=['target', 'predicted', 'count'], header=False, index=False)\n",
    "\n",
    "metadata = {\n",
    "'outputs' : [{\n",
    "  'type': 'confusion_matrix',\n",
    "  'format': 'csv',\n",
    "  'schema': [\n",
    "    {'name': 'target', 'type': 'CATEGORY'},\n",
    "    {'name': 'predicted', 'type': 'CATEGORY'},\n",
    "    {'name': 'count', 'type': 'NUMBER'},\n",
    "  ],\n",
    "  'source': 'conf_matr',\n",
    "  # Convert vocab to string because for bealean values we want \"True|False\" to match csv data.\n",
    "  'labels': list(map(str, vocab)),\n",
    "}]\n",
    "}\n",
    "\n",
    "print(\"meteadata: \",metadata)\n",
    "with open(\"metadata_out.json\", 'w+') as f1:\n",
    "    json.dump(metadata, f1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "metrics = {\n",
    "'metrics': [{\n",
    "  'name': 'accuracy-score',\n",
    "  'numberValue':  accuracy,\n",
    "  'format': \"PERCENTAGE\",\n",
    "}]\n",
    "}\n",
    "with open('metrics_out.json', 'w+') as f:\n",
    "    json.dump(metrics, f)\n",
    "    \n",
    "print(\"\\n\\n\\nmetrics: \",metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
