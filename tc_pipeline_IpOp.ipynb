{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data\n",
    "\n",
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def read_data(file_name: str, df_churn_op :OutputPath('CSV')): \n",
    "        \n",
    "    ## Import Required Libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    df_churn = pd.read_csv(file_name)\n",
    "    df_churn.to_csv(df_churn_op, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_read_data = kfp.components.func_to_container_op(func = read_data, \n",
    "                                                          output_component_file = './read-data-func.yaml',\n",
    "                                                          packages_to_install = ['numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def one_hot_encode(df_churn_ip: InputPath('CSV'), df_one_hot: OutputPath('CSV')):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    df_churn = pd.read_csv(df_churn_ip)\n",
    "    print(\"op started\")\n",
    "    empty_cols = ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "           'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "           'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport',\n",
    "           'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "           'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
    "\n",
    "    for i in empty_cols:\n",
    "        df_churn[i]=df_churn[i].replace(\" \",np.nan)\n",
    "\n",
    "    df_churn.drop(['customerID'], axis=1, inplace=True)\n",
    "    df_churn = df_churn.dropna()\n",
    "    binary_cols = ['Partner','Dependents','PhoneService','PaperlessBilling']\n",
    "\n",
    "    for i in binary_cols:\n",
    "        df_churn[i] = df_churn[i].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "    #Encoding column 'gender'\n",
    "    df_churn['gender'] = df_churn['gender'].replace({\"Male\":1,\"Female\":0})\n",
    "\n",
    "\n",
    "    category_cols = ['PaymentMethod','MultipleLines','InternetService','OnlineSecurity',\n",
    "                   'OnlineBackup','DeviceProtection',\n",
    "                   'TechSupport','StreamingTV','StreamingMovies','Contract']\n",
    "\n",
    "    for cc in category_cols:\n",
    "        dummies = pd.get_dummies(df_churn[cc], drop_first=False)\n",
    "        dummies = dummies.add_prefix(\"{}#\".format(cc))\n",
    "        df_churn.drop(cc, axis=1, inplace=True)\n",
    "        df_churn = df_churn.join(dummies)\n",
    "\n",
    "    df_churn['Churn'] = df_churn['Churn'].replace({\"Yes\":1,\"No\":0})\n",
    "    print(\"Encoding Complete\")\n",
    "\n",
    "    df_churn.to_csv(df_one_hot, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_one_hot_encode = kfp.components.func_to_container_op(func = one_hot_encode, \n",
    "                                                          output_component_file = './one-hot-encode-func.yaml',\n",
    "                                                          packages_to_install = ['scikit-learn==0.22.2','numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3',\n",
    "                                                                                 'imbalanced-learn==0.6.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "\n",
    "def rf_model(df_churn_ip: InputPath('CSV'), n_estimators: int) -> NamedTuple('Outputs', [('Cf1', int), ('Cf2', int),\n",
    "                                                                                     ('Cf3', int), ('Cf4', int)]):\n",
    "        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    #from imblearn.over_sampling import SMOTE\n",
    "    #from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import json\n",
    "    \n",
    "    df_churn = pd.read_csv(df_churn_ip)\n",
    "    print(\"op started\")\n",
    "    \n",
    "    df1 = df_churn.loc[:,:'Churn']\n",
    "    df1_int = df1[set(df1.columns)-{'tenure','MonthlyCharges','TotalCharges'}]\n",
    "    df1_float = df1[['tenure','MonthlyCharges','TotalCharges']]\n",
    "    df2 = df_churn.loc[:,'PaymentMethod#Bank transfer (automatic)':]\n",
    "\n",
    "    def get_item(a):\n",
    "        return int(a)\n",
    "\n",
    "    def get_fl(a):\n",
    "        return float(a)\n",
    "\n",
    "    df1_int = df1_int.applymap(get_item)\n",
    "    df1_float = df1_float.applymap(get_fl)\n",
    "    df2 = df2.applymap(get_item)\n",
    "    df_churn = df1_int.join(df1_float.join(df2))\n",
    "    df_churn.dropna(inplace=True)\n",
    "    \n",
    "    print(\"Converting done\")\n",
    "    n_est = n_estimators\n",
    "\n",
    "    y1 = df_churn['Churn']\n",
    "    X1 = df_churn.drop(['Churn'],axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)\n",
    "    \n",
    "    print(X_train.dtypes)\n",
    "    #converting pd datatypes to native python\n",
    "    X_int = X_train[set(X_train.columns)-{'tenure','MonthlyCharges','TotalCharges'}]\n",
    "    X_float = X_train[['tenure','MonthlyCharges','TotalCharges']]\n",
    "    X_int = X_int.applymap(get_item)\n",
    "    X_int = X_int.astype('int32')\n",
    "    X_float = X_float.applymap(get_fl)\n",
    "    X_float = X_float.astype('int32')\n",
    "    X_train = X_int.join(X_float)\n",
    "    \n",
    "    X_int = X_test[set(X_test.columns)-{'tenure','MonthlyCharges','TotalCharges'}]\n",
    "    X_float = X_test[['tenure','MonthlyCharges','TotalCharges']]\n",
    "    X_int = X_int.applymap(get_item)\n",
    "    X_int = X_int.astype('int32')\n",
    "    X_float = X_float.applymap(get_fl)\n",
    "    X_float = X_float.astype('int32')\n",
    "    X_test = X_int.join(X_float)\n",
    "    \n",
    "    y_train = y_train.apply(get_item)\n",
    "    y_train = y_train.astype('int32')\n",
    "    y_test = y_test.apply(get_item)\n",
    "    \n",
    "    print(\"tt done\")\n",
    "    print(X_train.dtypes)\n",
    "    print(y_train.dtype)\n",
    "#     sm y SMOTE(random_state=0)\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "#     X_test_res, y_test_res = sm.fit_sample(X_test, y_test)\n",
    "\n",
    "#     param_grid = {\n",
    "#         'n_estimators': [50, 100, 200],\n",
    "#         'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#         'max_depth' : [2,4,5,6,7,8],\n",
    "#         'criterion' :['gini', 'entropy']\n",
    "#     }\n",
    "    \n",
    "    n_est = n_estimators\n",
    "    \n",
    "#     rfc=RandomForestClassifier(random_state=42,n_estimators=n_est)\n",
    "#     gsv_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "#     rfc.fit(X_train_res, y_train_res)\n",
    "\n",
    "    rfc_best=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 50, max_depth=8,\n",
    "                                    criterion='gini')\n",
    "\n",
    "    rfc_best.fit(X_train, y_train) #(X_train_res, y_train_res)\n",
    "    #X_test_res, y_test_res = sm.fit_sample(X_test, y_test)\n",
    "    y_test_pred = rfc_best.predict(X_test) #_res)\n",
    "    rf_score = rfc_best.score(X_test, y_test)  #(X_test_res, y_test_res)\n",
    "    conf = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    return (conf[0][0],conf[0][1],conf[1][0],conf[1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_rf_model = kfp.components.func_to_container_op(func = rf_model, \n",
    "                                                          output_component_file = './rf-model-func.yaml', \n",
    "                                                   packages_to_install = ['scikit-learn==0.22.2','numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3',\n",
    "                                                                                 'imbalanced-learn==0.6.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def xgb_model(df_churn_ip: InputPath('CSV'), n_estimators: int) -> NamedTuple('Outputs', [('Cf1', int), ('Cf2', int),\n",
    "                                                                                     ('Cf3', int), ('Cf4', int)]):\n",
    "        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import xgboost as xgb\n",
    "\n",
    "    df_churn = pd.read_csv(df_churn_ip)\n",
    "    \n",
    "    df1 = df_churn.loc[:,:'Churn']\n",
    "    df1_int = df1[set(df1.columns)-{'tenure','MonthlyCharges','TotalCharges'}]\n",
    "    df1_float = df1[['tenure','MonthlyCharges','TotalCharges']]\n",
    "    df2 = df_churn.loc[:,'PaymentMethod#Bank transfer (automatic)':]\n",
    "\n",
    "    def get_item(a):\n",
    "        return int(a)\n",
    "\n",
    "    def get_fl(a):\n",
    "        return float(a)\n",
    "\n",
    "    df1_int = df1_int.applymap(get_item)\n",
    "    df1_float = df1_float.applymap(get_fl)\n",
    "    df2 = df2.applymap(get_item)\n",
    "    df_churn = df1_int.join(df1_float.join(df2))\n",
    "    df_churn.dropna(inplace=True)\n",
    "    \n",
    "    n_est = n_estimators\n",
    "    print(\"op started\")\n",
    "    y1 = df_churn['Churn']\n",
    "    X1 = df_churn.drop(['Churn'],axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)\n",
    "\n",
    "\n",
    "    sm = SMOTE(random_state=0)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    X_test_res, y_test_res = sm.fit_sample(X_test, y_test)\n",
    "\n",
    "    clfxg = xgb.XGBClassifier(objective='binary:logistic', verbosity=0, max_depth=2, eta = 1, silent=0)\n",
    "    clfxg.fit(X_train_res, y_train_res) #, num_round, watchlist)\n",
    "\n",
    "    y_test_pred = clfxg.predict(X_test_res)\n",
    "    conf = confusion_matrix(y_test_res, y_test_pred)\n",
    "\n",
    "    return conf[0][0], conf[0][1], conf[1][0], conf[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_xgb_model = kfp.components.func_to_container_op(func = xgb_model, \n",
    "                                                          output_component_file = './xgb-model-func.yaml',\n",
    "                                                          packages_to_install = ['scikit-learn==0.22.2','numpy==1.17.2',\n",
    "                                                                                 'pandas==1.0.3',\n",
    "                                                                                 'imbalanced-learn==0.6.2','xgboost==1.0.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "\n",
    "@dsl.pipeline(name='Read-Pipeline',description='ions using Random Forest Algorithm')\n",
    "def TChurn_func(f_n = \"https://raw.githubusercontent.com/rujual/telco_churn_pipeline/master/Data1.csv\", \n",
    "                n_estimators = 100):\n",
    "    \n",
    "    #Passing pipeline parameter and a constant value as operation arguments\n",
    "    read_data_task = kfp_read_data(file_name = f_n) \n",
    "    ohe_task = kfp_one_hot_encode(read_data_task.outputs['df_churn_op'])\n",
    "    rf_model_task = kfp_rf_model(ohe_task.outputs['df_one_hot'], n_estimators)\n",
    "    xgb_model_task = kfp_xgb_model(ohe_task.outputs['df_one_hot'], n_estimators)\n",
    "\n",
    "#For an operation with a single return value, the output reference can be accessed using `task.output` or `task.outputs['output_name']` syntax\n",
    "#For an operation with a multiple return values, the output references can be accessed using `task.outputs['output_name']` syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruju/anaconda3/lib/python3.7/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"100\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    }
   ],
   "source": [
    "pipeline_func = TChurn_func\n",
    "pipeline_filename = pipeline_func.__name__+'.pipeline.tar.gz'\n",
    "\n",
    "import kfp.compiler as comp\n",
    "comp.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
